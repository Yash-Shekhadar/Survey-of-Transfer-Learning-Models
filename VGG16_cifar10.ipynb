{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model on cifar10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D,MaxPooling2D,Dropout,Dense,Flatten, GlobalAveragePooling2D\n",
    "from keras import models,losses,optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3,VGG16,resnet50\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train,y_train),(X_test,y_test) = cifar10.load_data()\n",
    "#Converting y to categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(y_train).toarray().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print( X_train.shape, y_train.shape,  X_test.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building\n",
    "    - Importing the model\n",
    "    - Adding few layers on top of pretrained model\n",
    "    - Making the VGG16 Layers untrainable\n",
    "    - Compiling the model\n",
    "    - Summary of the model\n",
    "    - Fitting the model to train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = VGG16(include_top = False,weights='imagenet',input_shape = (32,32,3))\n",
    "model = models.Sequential()\n",
    "model.add(base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name='Dense_Intermediate'))\n",
    "model.add(Dropout(0.5, name='Dropout_Regularization'))\n",
    "model.add(Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnnlayer in model.layers[0].layers:\n",
    "    cnnlayer.trainable = False\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense_Intermediate (Dense)   (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "Dropout_Regularization (Drop (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 16,856,906\n",
      "Trainable params: 2,142,218\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.8689 - accuracy: 0.5045\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 1.2414 - accuracy: 0.5880\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 296s 6ms/step - loss: 1.1895 - accuracy: 0.6080\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 310s 6ms/step - loss: 1.1631 - accuracy: 0.6161\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 311s 6ms/step - loss: 1.1711 - accuracy: 0.6183\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 1.1413 - accuracy: 0.6296\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 1.1176 - accuracy: 0.6389\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 295s 6ms/step - loss: 1.0576 - accuracy: 0.6543\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 299s 6ms/step - loss: 1.0542 - accuracy: 0.6597\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 293s 6ms/step - loss: 1.0316 - accuracy: 0.6676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x246d60cf488>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning\n",
    "    - Unfreezing last 4 layers of VGG16 model\n",
    "    - Refitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000246D5C58C08> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D59544C8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D5938648> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000246D5937A48> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D5952688> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D5FF3988> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000246D5FF7688> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D5FFC308> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D5FFEE48> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D6002B48> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000246D600A0C8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D600AE48> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D60129C8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D60136C8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000246D6016D48> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D601A9C8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D6021548> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000246D60230C8> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000246D60268C8> True\n"
     ]
    }
   ],
   "source": [
    "for layer in base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "for layer in base.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 346s 7ms/step - loss: 1.0066 - accuracy: 0.6770\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 293s 6ms/step - loss: 0.9665 - accuracy: 0.6869\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 0.9482 - accuracy: 0.6948\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 0.9197 - accuracy: 0.7021\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 309s 6ms/step - loss: 0.9015 - accuracy: 0.7095\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.8812 - accuracy: 0.7176\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 294s 6ms/step - loss: 0.8617 - accuracy: 0.7219\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.8300 - accuracy: 0.7315\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.8157 - accuracy: 0.7400\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.7978 - accuracy: 0.7445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x246d6876f48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_mod = model.to_json()\n",
    "#Saving the model weights\n",
    "with open('model_VGG16.json','w') as file:\n",
    "    file.write(json_mod)\n",
    "model.save_weights('model_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_final = [ np.argmax( y_pred[i] ) for i in range(n_test) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = list(map(int,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(y_final) == np.array(y_val) ) /n_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Result\n",
    "    - Train Accuracy = 74.4 %\n",
    "    - Test Accuracy = 62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
